<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>How and Why Does Dropout Work? &#8212; Vikram&#39;s Data Science Blog</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=2a4ee713" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/fix_admonition_style.css?v=8627ce31" />
    <link rel="stylesheet" type="text/css" href="_static/fix_dropdown_style.css?v=f3461767" />
    <link rel="stylesheet" type="text/css" href="_static/fix_code_header_style.css?v=7d542921" />
    <link rel="stylesheet" type="text/css" href="_static/fix_sidebar_scroll.css?v=b9929681" />
    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="icon" href="_static/starburst (200 x 200 px).png"/>
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="How Does Batch Normalization Work? Part 1" href="how-batchnorm-works.html" />
    <link rel="prev" title="How do Positional Embeddings Work?" href="how-positional-embeddings-work.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section class="tex2jax_ignore mathjax_ignore" id="how-and-why-does-dropout-work">
<h1>How and Why Does Dropout Work?<a class="headerlink" href="#how-and-why-does-dropout-work" title="Link to this heading">¶</a></h1>
<section id="what-is-dropout">
<h2>What is Dropout?<a class="headerlink" href="#what-is-dropout" title="Link to this heading">¶</a></h2>
<p>The idea behind dropout is quite simple - during the training phase, a randomly selected subset of neurons is “dropped out” of the computation. This is achieved by setting their activations to 0. A fixed proportion <span class="math notranslate nohighlight">\(p\)</span>, usually between 10-50%, are “dropped out” during each training step. This value is often different for each layer.</p>
<p>During the testing phase, dropout is not applied, but instead, the outputs of each layer are scaled down by a factor of <span class="math notranslate nohighlight">\(1-p\)</span>.</p>
<p>Empirically, this results in improved generalization performance (i.e. on the validation or test set).</p>
<p>In this experiment, we will compare two deep neural networks, one without dropout and one with. Then, we will try to understand why dropout results in better performance.</p>
</section>
<section id="let-s-start-by-loading-the-cifar-10-dataset">
<h2>Let’s Start by Loading the CIFAR-10 Dataset<a class="headerlink" href="#let-s-start-by-loading-the-cifar-10-dataset" title="Link to this heading">¶</a></h2>
<p>The CIFAR-10 dataset is a popular benchmark for machine learning and computer vision tasks, consisting of 60,000 32x32 color images across 10 distinct classes. Each image is labeled as one of the following categories: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, or truck. The dataset is divided into 50,000 training images and 10,000 test images, with an even distribution of 6,000 images per class.</p>
<p>Despite its simplicity, the dataset contains a variety of object poses, lighting conditions, and backgrounds, making it non-trivial to achieve high accuracy.</p>
<p>Typicall, Convolutional Neural Networks and other image-specific architectures are used for this dataset. However, for this experiment, we will use a feedforward network in order to demonstrate the benefits of using dropout.</p>
<div class="cell tag_hide-input tag_skip-execution docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow_datasets</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tfds</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax.numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jnp</span>

<span class="n">train_tf</span><span class="p">,</span> <span class="n">test_tf</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;cifar10&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">as_supervised</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">raw_train_images</span><span class="p">,</span> <span class="n">train_labels</span> <span class="o">=</span> <span class="n">train_tf</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">train_tf</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">raw_train_images</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">raw_train_images</span><span class="p">)</span>
<span class="n">raw_train_images</span> <span class="o">=</span> <span class="n">raw_train_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">raw_train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span>

<span class="n">raw_test_images</span><span class="p">,</span> <span class="n">test_labels</span> <span class="o">=</span> <span class="n">test_tf</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">test_tf</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">raw_test_images</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">raw_test_images</span><span class="p">)</span>
<span class="n">raw_test_images</span> <span class="o">=</span> <span class="n">raw_test_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">raw_test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training Set Size </span><span class="si">{</span><span class="n">raw_train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test Set Size </span><span class="si">{</span><span class="n">raw_test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Set Size 50000
Test Set Size 10000
</pre></div>
</div>
</div>
</div>
<section id="what-does-our-dataset-look-like">
<h3>What Does Our Dataset Look Like?<a class="headerlink" href="#what-does-our-dataset-look-like" title="Link to this heading">¶</a></h3>
<p>Let’s look at a few training examples.</p>
<div class="cell tag_hide-input tag_skip-execution docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn-v0_8-darkgrid&#39;</span><span class="p">)</span>

<span class="n">RANDOM_KEY</span> <span class="o">=</span> <span class="mi">42</span>

<span class="n">num_examples</span> <span class="o">=</span> <span class="mi">25</span>
<span class="n">row_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">num_examples</span><span class="p">))</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">row_size</span><span class="p">,</span> <span class="n">row_size</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">row_size</span><span class="p">,</span><span class="n">row_size</span><span class="p">))</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">RANDOM_KEY</span><span class="p">)</span>
<span class="n">idxs</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="p">(</span><span class="n">num_examples</span><span class="p">,),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">raw_train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">exs</span> <span class="o">=</span> <span class="n">raw_train_images</span><span class="p">[</span><span class="n">idxs</span><span class="p">,:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">num_examples</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span><span class="o">/</span><span class="mf">255.0</span>

<span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_examples</span><span class="p">):</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">ex</span> <span class="o">//</span> <span class="n">row_size</span>
    <span class="n">j</span> <span class="o">=</span> <span class="n">ex</span> <span class="o">%</span> <span class="n">row_size</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">exs</span><span class="p">[</span><span class="n">ex</span><span class="p">])</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_xmargin</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_ymargin</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="_images/62c11e0a2a8f0f71e2cdfdd4c22ed1260f2074a37db0f4da16b529413c326d74.png" src="_images/62c11e0a2a8f0f71e2cdfdd4c22ed1260f2074a37db0f4da16b529413c326d74.png" />
</div>
</div>
<p>Let’s now preprocess the dataset and look at the input feature distrubition.</p>
<div class="cell tag_hide-input tag_skip-execution docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># First, let&#39;s plot the histogram for the unnormalized dataset</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">raw_train_images</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Unnormalized Input Feature Distribution&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Feature Values&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Counts&quot;</span><span class="p">)</span>

<span class="c1"># Let&#39;s normalize the  dataset</span>
<span class="n">train_mean</span> <span class="o">=</span> <span class="n">raw_train_images</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">train_std</span> <span class="o">=</span> <span class="n">raw_train_images</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="p">(</span><span class="n">raw_train_images</span> <span class="o">-</span> <span class="n">train_mean</span><span class="p">)</span><span class="o">/</span><span class="n">train_std</span>
<span class="n">train_max</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">/</span><span class="n">train_max</span>

<span class="n">test_mean</span> <span class="o">=</span> <span class="n">raw_test_images</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">test_std</span> <span class="o">=</span> <span class="n">raw_test_images</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="p">(</span><span class="n">raw_test_images</span> <span class="o">-</span> <span class="n">test_mean</span><span class="p">)</span><span class="o">/</span><span class="n">test_std</span>
<span class="n">test_max</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">/</span><span class="n">test_max</span>

<span class="c1"># Now let&#39;s plot the the histogram for the normalized dataset</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">train_images</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Normalized Input Feature Distribution&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Feature Values&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Counts&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="_images/835862d1a38a38ec28b0b001d160502b41febfd440366d7d282dc6645f0605e2.png" src="_images/835862d1a38a38ec28b0b001d160502b41febfd440366d7d282dc6645f0605e2.png" />
</div>
</div>
</section>
</section>
<section id="let-s-define-the-models">
<h2>Let’s Define the Models<a class="headerlink" href="#let-s-define-the-models" title="Link to this heading">¶</a></h2>
<p>Our baseline model is a fully-connected network with ReLU activations. The output layer has 10 classes to generate logits for our class probabilities.
The candidate is just the baseline with an additional dropout layer after each ReLU activation (except the final layer).</p>
<p>The dropout layer is placed after the ReLU activation because we want to only remove those neurons that participate in classifying an example. Removing neurons with zero or negative values will not serve this purpose. In fact, it may lead to ‘dead neurons’ which never activate.</p>
<div class="cell tag_skip-execution docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Any</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">reduce</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">operator</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">flax</span><span class="w"> </span><span class="kn">import</span> <span class="n">linen</span> <span class="k">as</span> <span class="n">nn</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">RANDOM_KEY</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="nd">@nn</span><span class="o">.</span><span class="n">compact</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>             
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Dense_0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm</span><span class="p">(</span><span class="n">use_running_average</span><span class="o">=</span><span class="ow">not</span> <span class="n">train</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>  
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;BatchNorm_0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Relu_0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>             
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Dense_1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm</span><span class="p">(</span><span class="n">use_running_average</span><span class="o">=</span><span class="ow">not</span> <span class="n">train</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>  
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;BatchNorm_1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Relu_1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>              
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Dense_2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm</span><span class="p">(</span><span class="n">use_running_average</span><span class="o">=</span><span class="ow">not</span> <span class="n">train</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>  
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;BatchNorm_2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Relu_2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>              
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Dense_3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm</span><span class="p">(</span><span class="n">use_running_average</span><span class="o">=</span><span class="ow">not</span> <span class="n">train</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>  
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;BatchNorm_3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Relu_3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>              
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Dense_4&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">outputs</span>

<span class="c1"># Initialize the candidate model</span>
<span class="n">baseline_model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">()</span>
<span class="n">dummy_input</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="o">*</span><span class="mi">32</span><span class="o">*</span><span class="mi">3</span><span class="p">))</span>
<span class="n">baseline_variables</span> <span class="o">=</span> <span class="n">baseline_model</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">dummy_input</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">baseline_params</span> <span class="o">=</span> <span class="n">baseline_variables</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]</span>
<span class="n">baseline_batch_stats</span> <span class="o">=</span> <span class="n">baseline_variables</span><span class="p">[</span><span class="s1">&#39;batch_stats&#39;</span><span class="p">]</span>
<span class="n">dropout</span><span class="o">=</span><span class="mf">0.4</span>

<span class="k">class</span><span class="w"> </span><span class="nc">MLPDropout</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="nd">@nn</span><span class="o">.</span><span class="n">compact</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">rng</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>             
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Dense_0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm</span><span class="p">(</span><span class="n">use_running_average</span><span class="o">=</span><span class="ow">not</span> <span class="n">train</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>  
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;BatchNorm_0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Relu_0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="ow">not</span> <span class="n">train</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Dropout_0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>             
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Dense_1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm</span><span class="p">(</span><span class="n">use_running_average</span><span class="o">=</span><span class="ow">not</span> <span class="n">train</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>  
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;BatchNorm_1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Relu_1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="ow">not</span> <span class="n">train</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Dropout_1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>              
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Dense_2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm</span><span class="p">(</span><span class="n">use_running_average</span><span class="o">=</span><span class="ow">not</span> <span class="n">train</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>  
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;BatchNorm_2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Relu_2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="ow">not</span> <span class="n">train</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Dropout_2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>              
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Dense_3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm</span><span class="p">(</span><span class="n">use_running_average</span><span class="o">=</span><span class="ow">not</span> <span class="n">train</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>  
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;BatchNorm_3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Relu_3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="ow">not</span> <span class="n">train</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Dropout_3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>              
        <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;Dense_4&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">outputs</span>

<span class="c1"># Initialize the candidate model</span>
<span class="n">candidate_model</span> <span class="o">=</span> <span class="n">MLPDropout</span><span class="p">()</span>
<span class="n">dummy_input</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="o">*</span><span class="mi">32</span><span class="o">*</span><span class="mi">3</span><span class="p">))</span>
<span class="n">candidate_variables</span> <span class="o">=</span> <span class="n">candidate_model</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">dummy_input</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="n">candidate_params</span> <span class="o">=</span> <span class="n">candidate_variables</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]</span>
<span class="n">candidate_batch_stats</span> <span class="o">=</span> <span class="n">candidate_variables</span><span class="p">[</span><span class="s1">&#39;batch_stats&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<section id="let-s-count-the-parameters-and-plot-the-initial-distributions-for-the-parameter-values">
<h3>Let’s count the parameters and plot the initial distributions for the parameter values.<a class="headerlink" href="#let-s-count-the-parameters-and-plot-the-initial-distributions-for-the-parameter-values" title="Link to this heading">¶</a></h3>
<div class="cell tag_hide-input tag_skip-execution docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Count the # of model parameters</span>
<span class="k">def</span><span class="w"> </span><span class="nf">count_params</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
    <span class="n">num_params</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">params</span><span class="p">[</span><span class="n">layer</span><span class="p">]:</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">num_params</span> <span class="o">+=</span> <span class="n">reduce</span><span class="p">(</span><span class="n">operator</span><span class="o">.</span><span class="n">mul</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">num_params</span>

<span class="n">num_baseline_params</span> <span class="o">=</span> <span class="n">count_params</span><span class="p">(</span><span class="n">baseline_params</span><span class="p">)</span>
<span class="n">num_candidate_params</span> <span class="o">=</span> <span class="n">count_params</span><span class="p">(</span><span class="n">candidate_params</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of baseline parameters: </span><span class="si">{</span><span class="n">num_baseline_params</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Baseline P/S ratio: </span><span class="si">{</span><span class="n">num_baseline_params</span><span class="o">/</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">0.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of candidate parameters: </span><span class="si">{</span><span class="n">num_candidate_params</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Candidate P/S ratio: </span><span class="si">{</span><span class="n">num_candidate_params</span><span class="o">/</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">0.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Lets plot the initial baseline model weight distributions</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>

<span class="n">baseline_dense0_w</span> <span class="o">=</span> <span class="n">baseline_params</span><span class="p">[</span><span class="s1">&#39;Dense_0&#39;</span><span class="p">][</span><span class="s1">&#39;kernel&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">candidate_dense0_w</span> <span class="o">=</span> <span class="n">candidate_params</span><span class="p">[</span><span class="s1">&#39;Dense_0&#39;</span><span class="p">][</span><span class="s1">&#39;kernel&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="n">baseline_dense1_w</span> <span class="o">=</span> <span class="n">baseline_params</span><span class="p">[</span><span class="s1">&#39;Dense_1&#39;</span><span class="p">][</span><span class="s1">&#39;kernel&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">candidate_dense1_w</span> <span class="o">=</span> <span class="n">candidate_params</span><span class="p">[</span><span class="s1">&#39;Dense_1&#39;</span><span class="p">][</span><span class="s1">&#39;kernel&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="n">baseline_dense2_w</span> <span class="o">=</span> <span class="n">baseline_params</span><span class="p">[</span><span class="s1">&#39;Dense_2&#39;</span><span class="p">][</span><span class="s1">&#39;kernel&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">candidate_dense2_w</span> <span class="o">=</span> <span class="n">candidate_params</span><span class="p">[</span><span class="s1">&#39;Dense_2&#39;</span><span class="p">][</span><span class="s1">&#39;kernel&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="n">baseline_dense3_w</span> <span class="o">=</span> <span class="n">baseline_params</span><span class="p">[</span><span class="s1">&#39;Dense_3&#39;</span><span class="p">][</span><span class="s1">&#39;kernel&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">candidate_dense3_w</span> <span class="o">=</span> <span class="n">candidate_params</span><span class="p">[</span><span class="s1">&#39;Dense_3&#39;</span><span class="p">][</span><span class="s1">&#39;kernel&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">baseline_dense0_w</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Dense_0 Weights&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Baseline&quot;</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">baseline_dense1_w</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Dense_1 Weights&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Baseline&quot;</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">baseline_dense2_w</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Dense_2 Weights&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Baseline&quot;</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">baseline_dense3_w</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Dense_3 Weights&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Baseline&quot;</span><span class="p">])</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">candidate_dense0_w</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Candidate&quot;</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">candidate_dense1_w</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Candidate&quot;</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">candidate_dense2_w</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Candidate&quot;</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">candidate_dense3_w</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Candidate&quot;</span><span class="p">])</span>



<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of baseline parameters: 831210
Baseline P/S ratio: 16.6242
Number of candidate parameters: 831210
Candidate P/S ratio: 16.6242
</pre></div>
</div>
<img alt="_images/b971e41e4a8503789177551ba2746f9f29cd6d255a08e95914d33d8263105bbb.png" src="_images/b971e41e4a8503789177551ba2746f9f29cd6d255a08e95914d33d8263105bbb.png" />
</div>
</div>
<p>As you can see, both models have the same number of parameters as well as initial distributions. Hence, we can safely assume that any performance improvement seen by the candidate model will be due to dropout.</p>
<div class="cell tag_hide-input tag_skip-execution docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tempfile</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">try</span><span class="p">:</span>
    <span class="nb">type</span><span class="p">(</span><span class="n">tmpdir</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="n">base_temp_dir</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">gettempdir</span><span class="p">()</span>
    <span class="n">tmpdir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_temp_dir</span><span class="p">,</span> <span class="s2">&quot;model_outputs&quot;</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">tmpdir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">save_accuracy_to_disk</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">phase</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">tmpdir</span><span class="o">=</span><span class="n">tmpdir</span><span class="p">):</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">tmpdir</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">phase</span><span class="si">}</span><span class="s1">_accuracy.npy&#39;</span>
        <span class="n">jnp</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">metrics</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">load_accuracy_from_disk</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">phase</span><span class="p">,</span> <span class="n">tmpdir</span><span class="o">=</span><span class="n">tmpdir</span><span class="p">):</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">tmpdir</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">phase</span><span class="si">}</span><span class="s1">_accuracy.npy&#39;</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">save_outputs_to_disk</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">phase</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">tmpdir</span><span class="o">=</span><span class="n">tmpdir</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">tmpdir</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">phase</span><span class="si">}</span><span class="s1">_outputs_epoch_</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">.npz&#39;</span>
        <span class="n">jnp</span><span class="o">.</span><span class="n">savez</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>


<span class="k">def</span><span class="w"> </span><span class="nf">load_outputs_from_disk</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">phase</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">layer</span><span class="p">,</span> <span class="n">tmpdir</span><span class="o">=</span><span class="n">tmpdir</span><span class="p">):</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">tmpdir</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">phase</span><span class="si">}</span><span class="s1">_outputs_epoch_</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">layer</span><span class="si">}</span><span class="s1">.npz&#39;</span>
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="p">)[</span><span class="s1">&#39;arr_0&#39;</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1">#print(f&quot;No data found for file {filename}&quot;)</span>
        <span class="k">return</span> <span class="kc">None</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell tag_hide-input tag_skip-execution docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="nb">type</span><span class="p">(</span><span class="n">tmpdir</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="n">tmpdir</span> <span class="o">=</span> <span class="s2">&quot;/var/folders/x4/85_9sn3d1ng9q48ff6t3fw340000gn/T/model_outputs&quot;</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<section id="let-s-train-the-baseline-model">
<h2>Let’s Train the Baseline Model<a class="headerlink" href="#let-s-train-the-baseline-model" title="Link to this heading">¶</a></h2>
<div class="cell tag_skip-execution docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">optax</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">flax.training</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_state</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">RANDOM_KEY</span><span class="p">)</span>
<span class="n">LR</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_skip-execution docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a train state</span>
<span class="n">tx</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">)</span>
<span class="n">baseline_ts</span> <span class="o">=</span> <span class="n">train_state</span><span class="o">.</span><span class="n">TrainState</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">apply_fn</span><span class="o">=</span><span class="n">baseline_model</span><span class="o">.</span><span class="n">apply</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">baseline_params</span><span class="p">,</span> <span class="n">tx</span><span class="o">=</span><span class="n">tx</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">compute_loss</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">batch_stats</span><span class="p">,</span> <span class="n">apply_fn</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">train</span><span class="p">):</span>
    <span class="n">variables</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">params</span><span class="p">,</span> <span class="s1">&#39;batch_stats&#39;</span><span class="p">:</span> <span class="n">batch_stats</span><span class="p">}</span>
    <span class="n">outputs</span><span class="p">,</span> <span class="n">updated_variables</span> <span class="o">=</span> <span class="n">apply_fn</span><span class="p">(</span><span class="n">variables</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="n">mutable</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;batch_stats&#39;</span><span class="p">])</span>
    <span class="n">logits</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">outputs</span>
    <span class="n">one_hot_labels</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">softmax_cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">one_hot_labels</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">updated_variables</span><span class="p">[</span><span class="s1">&#39;batch_stats&#39;</span><span class="p">]</span>

<span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">batch_stats</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">loss_fn</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">compute_loss</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">batch_stats</span><span class="p">,</span> <span class="n">state</span><span class="o">.</span><span class="n">apply_fn</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">grads</span><span class="p">,</span> <span class="n">updated_batch_stats</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">has_aux</span><span class="o">=</span><span class="kc">True</span><span class="p">)(</span><span class="n">state</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">grads</span><span class="o">=</span><span class="n">grads</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">grads</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">updated_batch_stats</span>

<span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">eval_step</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">batch_stats</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">variables</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">state</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="s1">&#39;batch_stats&#39;</span><span class="p">:</span> <span class="n">batch_stats</span><span class="p">}</span>
    <span class="n">logits</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">apply_fn</span><span class="p">(</span><span class="n">variables</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">outputs</span>


<span class="k">def</span><span class="w"> </span><span class="nf">train_and_evaluate</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">ts</span><span class="p">,</span> <span class="n">batch_stats</span><span class="p">,</span> <span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">):</span>

    <span class="n">num_train</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">train_accuracy</span><span class="p">,</span> <span class="n">train_outputs</span> <span class="o">=</span> <span class="n">eval_step</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">batch_stats</span><span class="p">,</span> <span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)</span>
    <span class="n">save_outputs_to_disk</span><span class="p">(</span><span class="s2">&quot;Baseline&quot;</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;0&quot;</span><span class="p">,</span> <span class="n">train_outputs</span><span class="p">)</span>
    <span class="n">train_outputs</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">test_outputs</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">test_accuracy</span><span class="p">,</span> <span class="n">test_outputs</span> <span class="o">=</span> <span class="n">eval_step</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">batch_stats</span><span class="p">,</span> <span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
    <span class="n">save_outputs_to_disk</span><span class="p">(</span><span class="s2">&quot;Baseline&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="s2">&quot;0&quot;</span><span class="p">,</span> <span class="n">test_outputs</span><span class="p">)</span>
    <span class="n">train_accuracy_history</span> <span class="o">=</span> <span class="p">[</span><span class="n">train_accuracy</span><span class="p">]</span>
    <span class="n">test_accuracy_history</span> <span class="o">=</span> <span class="p">[</span><span class="n">test_accuracy</span><span class="p">]</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch 0, Train Accuracy: </span><span class="si">{</span><span class="n">train_accuracy</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">, Test Accuracy: </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>

        <span class="n">rng</span><span class="p">,</span> <span class="n">sub_rng</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span>
        <span class="n">permutation</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">sub_rng</span><span class="p">,</span> <span class="n">num_train</span><span class="p">)</span>
        <span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="p">[</span><span class="n">permutation</span><span class="p">]</span>
        <span class="n">train_labels</span> <span class="o">=</span> <span class="n">train_labels</span><span class="p">[</span><span class="n">permutation</span><span class="p">]</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">batch_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
            <span class="n">batch_labels</span> <span class="o">=</span> <span class="n">train_labels</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
            <span class="n">grads</span><span class="p">,</span> <span class="n">ts</span><span class="p">,</span> <span class="n">batch_stats</span> <span class="o">=</span> <span class="n">train_step</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">batch_stats</span><span class="p">,</span> <span class="n">batch_images</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">)</span>

        <span class="n">train_accuracy</span><span class="p">,</span> <span class="n">train_outputs</span> <span class="o">=</span> <span class="n">eval_step</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">batch_stats</span><span class="p">,</span> <span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)</span>
        <span class="n">test_accuracy</span><span class="p">,</span> <span class="n">test_outputs</span> <span class="o">=</span> <span class="n">eval_step</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">batch_stats</span><span class="p">,</span> <span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">save_outputs_to_disk</span><span class="p">(</span><span class="s2">&quot;Baseline&quot;</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_outputs</span><span class="p">)</span>
            <span class="n">save_outputs_to_disk</span><span class="p">(</span><span class="s2">&quot;Baseline&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">test_outputs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">, Train Accuracy: </span><span class="si">{</span><span class="n">train_accuracy</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">, Test Accuracy: </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">train_accuracy_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_accuracy</span><span class="p">)</span>
        <span class="n">test_accuracy_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_accuracy</span><span class="p">)</span>

        <span class="n">train_outputs</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">test_outputs</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s1">, Train Accuracy: </span><span class="si">{</span><span class="n">train_accuracy_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">, Test Accuracy: </span><span class="si">{</span><span class="n">test_accuracy_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="n">save_accuracy_to_disk</span><span class="p">(</span><span class="s2">&quot;Baseline&quot;</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="n">train_accuracy_history</span><span class="p">)</span>
    <span class="n">save_accuracy_to_disk</span><span class="p">(</span><span class="s2">&quot;Baseline&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">test_accuracy_history</span><span class="p">)</span>

<span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">baseline_ts</span><span class="p">,</span> <span class="n">baseline_batch_stats</span><span class="p">,</span> <span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 0, Train Accuracy: 0.1096, Test Accuracy: 0.1108
Epoch 1, Train Accuracy: 0.4692, Test Accuracy: 0.4593
Epoch 51, Train Accuracy: 0.9252, Test Accuracy: 0.5441
Epoch 101, Train Accuracy: 0.9718, Test Accuracy: 0.5348
Epoch 151, Train Accuracy: 0.9854, Test Accuracy: 0.5276
Epoch 200, Train Accuracy: 0.9921, Test Accuracy: 0.5258
</pre></div>
</div>
</div>
</div>
</section>
<section id="next-let-s-train-the-candidate-model">
<h2>Next, Let’s Train the Candidate Model<a class="headerlink" href="#next-let-s-train-the-candidate-model" title="Link to this heading">¶</a></h2>
<div class="cell tag_skip-execution docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a train state</span>
<span class="n">tx</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">LR</span><span class="p">)</span>
<span class="n">candidate_ts</span> <span class="o">=</span> <span class="n">train_state</span><span class="o">.</span><span class="n">TrainState</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">apply_fn</span><span class="o">=</span><span class="n">candidate_model</span><span class="o">.</span><span class="n">apply</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">candidate_params</span><span class="p">,</span> <span class="n">tx</span><span class="o">=</span><span class="n">tx</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">compute_loss</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">batch_stats</span><span class="p">,</span> <span class="n">apply_fn</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">rng</span><span class="p">):</span>
    <span class="n">variables</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">params</span><span class="p">,</span> <span class="s1">&#39;batch_stats&#39;</span><span class="p">:</span> <span class="n">batch_stats</span><span class="p">}</span>
    <span class="n">outputs</span><span class="p">,</span> <span class="n">updated_variables</span> <span class="o">=</span> <span class="n">apply_fn</span><span class="p">(</span><span class="n">variables</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span>  <span class="n">mutable</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;batch_stats&#39;</span><span class="p">])</span>
    <span class="n">logits</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">outputs</span>
    <span class="n">one_hot_labels</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">softmax_cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">one_hot_labels</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">updated_variables</span><span class="p">[</span><span class="s1">&#39;batch_stats&#39;</span><span class="p">]</span>

<span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">train_step</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">batch_stats</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">rng</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">loss_fn</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">compute_loss</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">batch_stats</span><span class="p">,</span> <span class="n">state</span><span class="o">.</span><span class="n">apply_fn</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
    <span class="n">grads</span><span class="p">,</span> <span class="n">updated_batch_stats</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">has_aux</span><span class="o">=</span><span class="kc">True</span><span class="p">)(</span><span class="n">state</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">grads</span><span class="o">=</span><span class="n">grads</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">grads</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">updated_batch_stats</span>

<span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">eval_step</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">batch_stats</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">rng</span><span class="p">):</span>
    <span class="n">variables</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">state</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="s1">&#39;batch_stats&#39;</span><span class="p">:</span> <span class="n">batch_stats</span><span class="p">}</span>
    <span class="n">logits</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">apply_fn</span><span class="p">(</span><span class="n">variables</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">outputs</span>


<span class="k">def</span><span class="w"> </span><span class="nf">train_and_evaluate</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">ts</span><span class="p">,</span> <span class="n">batch_stats</span><span class="p">,</span> <span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">):</span>

    <span class="n">num_train</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">train_accuracy</span><span class="p">,</span> <span class="n">train_outputs</span> <span class="o">=</span> <span class="n">eval_step</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">batch_stats</span><span class="p">,</span> <span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">rng</span><span class="p">)</span>
    <span class="n">save_outputs_to_disk</span><span class="p">(</span><span class="s2">&quot;Candidate&quot;</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;0&quot;</span><span class="p">,</span> <span class="n">train_outputs</span><span class="p">)</span>
    <span class="n">test_accuracy</span><span class="p">,</span> <span class="n">test_outputs</span> <span class="o">=</span> <span class="n">eval_step</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">batch_stats</span><span class="p">,</span> <span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">rng</span><span class="p">)</span>
    <span class="n">save_outputs_to_disk</span><span class="p">(</span><span class="s2">&quot;Candidate&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="s2">&quot;0&quot;</span><span class="p">,</span> <span class="n">test_outputs</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch 0, Train Accuracy: </span><span class="si">{</span><span class="n">train_accuracy</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">, Test Accuracy: </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">train_accuracy_history</span> <span class="o">=</span> <span class="p">[</span><span class="n">train_accuracy</span><span class="p">]</span>
    <span class="n">test_accuracy_history</span> <span class="o">=</span> <span class="p">[</span><span class="n">test_accuracy</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>

        <span class="n">rng</span><span class="p">,</span> <span class="n">sub_rng</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span>
        <span class="n">permutation</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">sub_rng</span><span class="p">,</span> <span class="n">num_train</span><span class="p">)</span>
        <span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="p">[</span><span class="n">permutation</span><span class="p">]</span>
        <span class="n">train_labels</span> <span class="o">=</span> <span class="n">train_labels</span><span class="p">[</span><span class="n">permutation</span><span class="p">]</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">batch_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
            <span class="n">batch_labels</span> <span class="o">=</span> <span class="n">train_labels</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
            <span class="n">grads</span><span class="p">,</span> <span class="n">ts</span><span class="p">,</span> <span class="n">batch_stats</span> <span class="o">=</span> <span class="n">train_step</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">batch_stats</span><span class="p">,</span> <span class="n">batch_images</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">,</span> <span class="n">sub_rng</span><span class="p">)</span>

        <span class="n">train_accuracy</span><span class="p">,</span> <span class="n">train_outputs</span> <span class="o">=</span> <span class="n">eval_step</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">batch_stats</span><span class="p">,</span> <span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">sub_rng</span><span class="p">)</span>
        <span class="n">test_accuracy</span><span class="p">,</span> <span class="n">test_outputs</span> <span class="o">=</span> <span class="n">eval_step</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">batch_stats</span><span class="p">,</span> <span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">sub_rng</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">save_outputs_to_disk</span><span class="p">(</span><span class="s2">&quot;Candidate&quot;</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_outputs</span><span class="p">)</span>
            <span class="n">save_outputs_to_disk</span><span class="p">(</span><span class="s2">&quot;Candidate&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">test_outputs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">, Train Accuracy: </span><span class="si">{</span><span class="n">train_accuracy</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">, Test Accuracy: </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">train_accuracy_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_accuracy</span><span class="p">)</span>
        <span class="n">test_accuracy_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_accuracy</span><span class="p">)</span>

    <span class="n">save_accuracy_to_disk</span><span class="p">(</span><span class="s2">&quot;Candidate&quot;</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="n">train_accuracy_history</span><span class="p">)</span>
    <span class="n">save_accuracy_to_disk</span><span class="p">(</span><span class="s2">&quot;Candidate&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">test_accuracy_history</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s1">, Train Accuracy: </span><span class="si">{</span><span class="n">train_accuracy_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">, Test Accuracy: </span><span class="si">{</span><span class="n">test_accuracy_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">candidate_ts</span><span class="p">,</span> <span class="n">candidate_batch_stats</span><span class="p">,</span> <span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 0, Train Accuracy: 0.1096, Test Accuracy: 0.1108
Epoch 1, Train Accuracy: 0.4253, Test Accuracy: 0.4278
Epoch 51, Train Accuracy: 0.6953, Test Accuracy: 0.5547
Epoch 101, Train Accuracy: 0.7653, Test Accuracy: 0.5547
Epoch 151, Train Accuracy: 0.8072, Test Accuracy: 0.5597
Epoch 200, Train Accuracy: 0.8342, Test Accuracy: 0.5558
</pre></div>
</div>
</div>
</div>
<p>Let’s look at the accuracy metrics over time.</p>
<div class="cell tag_hide-input tag_skip-execution docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>

<span class="n">baseline_train_accuracy_history</span> <span class="o">=</span> <span class="n">load_accuracy_from_disk</span><span class="p">(</span><span class="s2">&quot;Baseline&quot;</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">)</span>
<span class="n">baseline_test_accuracy_history</span> <span class="o">=</span> <span class="n">load_accuracy_from_disk</span><span class="p">(</span><span class="s2">&quot;Baseline&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">)</span>
<span class="n">candidate_train_accuracy_history</span> <span class="o">=</span> <span class="n">load_accuracy_from_disk</span><span class="p">(</span><span class="s2">&quot;Candidate&quot;</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">)</span>
<span class="n">candidate_test_accuracy_history</span> <span class="o">=</span> <span class="n">load_accuracy_from_disk</span><span class="p">(</span><span class="s2">&quot;Candidate&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">baseline_train_accuracy_history</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">candidate_train_accuracy_history</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Train Accuracy&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Baseline&quot;</span><span class="p">,</span> <span class="s2">&quot;Candidate&quot;</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">baseline_test_accuracy_history</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">candidate_test_accuracy_history</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Test Accuracy&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Baseline&quot;</span><span class="p">,</span> <span class="s2">&quot;Candidate&quot;</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.6</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="_images/f18aea9feffdc0628a9447499866e741825262c039858a8e70c3b08ddb4af7f5.png" src="_images/f18aea9feffdc0628a9447499866e741825262c039858a8e70c3b08ddb4af7f5.png" />
</div>
</div>
<p>As you can see, the candidate model with the dropout layers performs better than the baseline. It also takes longer to converge than the baseline.</p>
</section>
<section id="so-why-does-dropout-help">
<h2>So Why Does Dropout Help?<a class="headerlink" href="#so-why-does-dropout-help" title="Link to this heading">¶</a></h2>
<section id="regularization-noise-addition">
<h3>Regularization / Noise Addition<a class="headerlink" href="#regularization-noise-addition" title="Link to this heading">¶</a></h3>
<p>Notice that the baseline model tends to overfit considerably more on the training data, reaching a training accuracy of 99%, but lagging behind the candidate in terms of test set performance.</p>
<p>This is because dropout can be seen as a way of adding noise, which prevents the model from overfitting to the specific training examples and forces it to learn more general patterns, thus improving test performance.</p>
<p>It can also be seen as a form of regularization, which means that the addition of noise makes the model more robust to small changes in the input distribution.</p>
</section>
<section id="sparse-activations">
<h3>Sparse Activations<a class="headerlink" href="#sparse-activations" title="Link to this heading">¶</a></h3>
<p>Let’s plot the number of activated neurons per training example over time.</p>
<div class="cell tag_hide-input tag_skip-execution docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_activation_stats</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">phase</span><span class="p">,</span> <span class="n">layer</span><span class="p">):</span>
    <span class="n">baseline_activation_counts</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">baseline_dead_neuron_counts</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">baseline_outputs</span> <span class="o">=</span>  <span class="n">load_outputs_from_disk</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">phase</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">baseline_outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">baseline_datapoints</span> <span class="o">=</span> <span class="n">baseline_outputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">active_baseline_outputs</span> <span class="o">=</span> <span class="n">baseline_outputs</span><span class="p">[</span><span class="n">baseline_outputs</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>
            <span class="n">bcount</span> <span class="o">=</span> <span class="n">active_baseline_outputs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">baseline_datapoints</span>
            <span class="n">baseline_activation_counts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bcount</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">baseline_activation_counts</span><span class="p">,</span> <span class="n">baseline_dead_neuron_counts</span>


<span class="n">fix</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">6</span><span class="p">,</span><span class="mi">5</span><span class="o">*</span><span class="mi">4</span><span class="p">])</span>

<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>

    <span class="n">baseline_test_activation_counts</span><span class="p">,</span> <span class="n">baseline_test_dead_neuron_counts</span> <span class="o">=</span> <span class="n">get_activation_stats</span><span class="p">(</span><span class="s2">&quot;Baseline&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Relu_</span><span class="si">{</span><span class="n">layer</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">candidate_test_activation_counts</span><span class="p">,</span> <span class="n">candidate_test_dead_neuron_counts</span> <span class="o">=</span> <span class="n">get_activation_stats</span><span class="p">(</span><span class="s2">&quot;Candidate&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Dropout_</span><span class="si">{</span><span class="n">layer</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> 

    <span class="n">ax</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">201</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">baseline_test_activation_counts</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">201</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">candidate_test_activation_counts</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Layer Dense_</span><span class="si">{</span><span class="n">layer</span><span class="si">}</span><span class="s2"> Activation Counts (Test)&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Activations on the Test Set&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Baseline&quot;</span><span class="p">,</span> <span class="s2">&quot;Candidate (Dropout)&quot;</span><span class="p">])</span>


<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="_images/f7b683a78607c71f87eec3a1211d003e8eeddc3757c497434c0b59aa1411a81e.png" src="_images/f7b683a78607c71f87eec3a1211d003e8eeddc3757c497434c0b59aa1411a81e.png" />
</div>
</div>
<p>Notice that both the baseline and candidate models have similar numbers of activated neurons at the start of training. However, as training progresses, the candidate model tends to have fewer activations per training example. Dropout thus encourages sparse representations, which, as we saw in the results, also tend to be more robust to changes in the inputs (i.e. regularization).</p>
<p>In the baseline model, a neuron tends to co-adapt to other specific neurons, which leads to overfitting. By using dropout, a neuron cannot necessarily depend on other units and has to individually learn a more robust function.</p>
<p>Next, let’s look at the activation statistics.</p>
<div class="cell tag_hide-input tag_skip-execution docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">5</span><span class="o">*</span><span class="mi">4</span><span class="p">))</span>

<span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>

    <span class="n">baseline_output_means</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">baseline_output_stds</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">candidate_output_means</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">candidate_output_stds</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">baseline_o1</span> <span class="o">=</span> <span class="n">load_outputs_from_disk</span><span class="p">(</span><span class="s2">&quot;Baseline&quot;</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Relu_</span><span class="si">{</span><span class="n">l</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">baseline_o1</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">baseline_m1</span> <span class="o">=</span> <span class="n">baseline_o1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="n">baseline_output_means</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">baseline_m1</span><span class="p">)</span>
            <span class="n">baseline_s1</span> <span class="o">=</span> <span class="n">baseline_o1</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
            <span class="n">baseline_output_stds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">baseline_s1</span><span class="p">)</span>
        
        <span class="n">candidate_o1</span> <span class="o">=</span> <span class="n">load_outputs_from_disk</span><span class="p">(</span><span class="s2">&quot;Candidate&quot;</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Dropout_</span><span class="si">{</span><span class="n">l</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">candidate_o1</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">candidate_m1</span> <span class="o">=</span> <span class="n">candidate_o1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="n">candidate_output_means</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">candidate_m1</span><span class="p">)</span>
            <span class="n">candidate_s1</span> <span class="o">=</span> <span class="n">candidate_o1</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
            <span class="n">candidate_output_stds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">candidate_s1</span><span class="p">)</span>

    <span class="n">axs</span><span class="p">[</span><span class="n">l</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Layer Dense_</span><span class="si">{</span><span class="n">l</span><span class="si">}</span><span class="s2"> Outputs (Mean)&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">l</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Train Epoch&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">l</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">201</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="n">baseline_output_means</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">l</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">201</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="n">candidate_output_means</span><span class="p">)</span>

    <span class="n">axs</span><span class="p">[</span><span class="n">l</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Layer Dense_</span><span class="si">{</span><span class="n">l</span><span class="si">}</span><span class="s2"> Outputs (Standard Deviation)&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">l</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Train Epoch&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">l</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">201</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="n">baseline_output_stds</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">l</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">201</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="n">candidate_output_stds</span><span class="p">)</span>

    <span class="n">axs</span><span class="p">[</span><span class="n">l</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Baseline&quot;</span><span class="p">,</span> <span class="s2">&quot;Candidate&quot;</span><span class="p">])</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">l</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Baseline&quot;</span><span class="p">,</span> <span class="s2">&quot;Candidate&quot;</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="_images/e00f43a205df6fb99493a4d1744aed3826602cd6859866f284064762a82dec31.png" src="_images/e00f43a205df6fb99493a4d1744aed3826602cd6859866f284064762a82dec31.png" />
</div>
</div>
<p>Notice that both the mean and standard deviation of the baseline activations increase as training progressses. However, the candidate activation statistics tend to stabilize and even decrease.</p>
<p>Let’s confirm this by comparing activation histograms.</p>
<div class="cell tag_hide-input tag_skip-execution docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">baseline_all_outputs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">candidate_all_outputs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">200</span>
<span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">load_outputs_from_disk</span><span class="p">(</span><span class="s2">&quot;Baseline&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Relu_</span><span class="si">{</span><span class="n">l</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">baseline_all_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">load_outputs_from_disk</span><span class="p">(</span><span class="s2">&quot;Candidate&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Relu_</span><span class="si">{</span><span class="n">l</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">candidate_all_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>


<span class="n">baseline_all_outputs</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">baseline_all_outputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  
<span class="n">candidate_all_outputs</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">candidate_all_outputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell tag_hide-input tag_skip-execution docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">baseline_all_outputs</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">0.00</span><span class="p">,</span><span class="mf">4.0</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">1e6</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Baseline Positive Activations (Test)&quot;</span><span class="p">)</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">candidate_all_outputs</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">0.00</span><span class="p">,</span><span class="mf">4.0</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.1e7</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Candidate Positive Activations (Test)&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="_images/60c3c54a9091a6c12d8b06bca094b355f1ddba49832a893a335a0903c40aaf31.png" src="_images/60c3c54a9091a6c12d8b06bca094b355f1ddba49832a893a335a0903c40aaf31.png" />
</div>
</div>
<p>It’s clear that the baseline activations are more spread out than the candidate ones, which are more sparse and smaller in magnitude. Thus, not only are fewer neurons activated per example, but the magnitudes of the activations themselves are diminished. This is due to the network having learned to avoid overly depending on specific neurons across training examples.</p>
</section>
<section id="ensembling">
<h3>Ensembling<a class="headerlink" href="#ensembling" title="Link to this heading">¶</a></h3>
<p>Dropout can also be seen as a way of creating an ensemble of models with shared weights. Mathematically, a single neural network with dropout is an ensemble of <span class="math notranslate nohighlight">\(2^n\)</span> models, where <span class="math notranslate nohighlight">\(n\)</span> is the number of neurons. Each model in this ensemble is selected for a training step with a probability of <span class="math notranslate nohighlight">\((1-p)^k\)</span>, where <span class="math notranslate nohighlight">\(k\)</span> is the size of the model.</p>
<p>In the light of this, we can explain the fewer and sparser activations as smaller sub-networks specializing in recognizing specific types of examples.</p>
</section>
<section id="references">
<h3>References:<a class="headerlink" href="#references" title="Link to this heading">¶</a></h3>
<ol class="arabic simple">
<li><p>Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., &amp; Salakhutdinov, R. (2014). Dropout: A simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15(1).</p></li>
<li><p>Baldi, P., &amp; Sadowski, P. (2013). Understanding dropout. Advances in Neural Information Processing Systems, 26.</p></li>
<li><p>Sutskever, I., Martens, J., Dahl, G., &amp; Hinton, G. (2013). On the importance of initialization and momentum in deep learning. In Proceedings of the 30th International Conference on Machine Learning (ICML-13).</p></li>
<li><p>Nair, V., &amp; Hinton, G. E. (2010). Rectified linear units improve restricted Boltzmann machines. In Proceedings of the 27th International Conference on Machine Learning (ICML-10).</p></li>
</ol>
<script src="https://utteranc.es/client.js"
        repo="novastar53/novastar53.github.io"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script></section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="intro.html">
              <img class="logo" src="_static/starburst-transparent.png" alt="Logo of Starburst Data Science Blog"/>
            </a></p>
<h1 class="logo"><a href="intro.html">Starburst Data Science Blog</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="how-batchnorm-works-part-2.html">How Does Batch Normalization Work? Part 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="how-residual-connections-work.html">How Do Residual Connections Work?</a></li>
<li class="toctree-l1"><a class="reference internal" href="how-positional-embeddings-work.html">How do Positional Embeddings Work?</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">How and Why Does Dropout Work?</a></li>
<li class="toctree-l1"><a class="reference internal" href="how-batchnorm-works.html">How Does Batch Normalization Work? Part 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="nadaraya-watson-kernel-regression.html">Nadaraya-Watson Regression</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="intro.html">Documentation overview</a><ul>
      <li>Previous: <a href="how-positional-embeddings-work.html" title="previous chapter">How do Positional Embeddings Work?</a></li>
      <li>Next: <a href="how-batchnorm-works.html" title="next chapter">How Does Batch Normalization Work? Part 1</a></li>
  </ul></li>
</ul>
</div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;Vikram Pawar novastar53.github.io.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.4.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="_sources/how-dropout-works.ipynb"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>