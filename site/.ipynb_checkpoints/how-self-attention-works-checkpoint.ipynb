{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How and Why does Self Attention Work? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Non-Linear Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prevailing paradigm in machine learning is to repeatedly perform the same non-linear transformation, initially on the input data, and then on the outputs successively. Each of these transformations is called a layer. Deep architectures are so called because they have many such layers. For example, the GPT-3 model trained at OpenAI had 96 layers in total. \n",
    "\n",
    "Many of the key breakthroughs in recent years have focused on resolving some of the problems that crop up while trying to train such architectures. I have covered a few of these in previous posts, such as [Batch Normalization](...) and [Dropout](...).\n",
    "\n",
    "The earliest deep-learning architecture was what is now called a Feed-Forward Network, which in its current mature formulation, consists of a linear operation followed by a non-linear activation function $(\\sigma)$ such as ReLU (Rectified Linear Unit).\n",
    "\n",
    "$$\n",
    "f(\\bold{x}) = \\sigma(\\bold{Wx} + b)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"nn.svg\" alt=\"Feed Forward Network\" style=\"width:500px;\"/>\n",
    "\n",
    "Another popular architecture used primarily in computer vision is the Convolutional Neural Network (CNN), whose basic transformation is the convolution followed by an activation function. The idea here is that the model can learn to detect features in an image by performing non-linear transformations on small patches of the image. Then, just like the basic Feed-Forward network, the same operation can be performed on the outputs successively.\n",
    "\n",
    "I won't go into to much detail on these here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A New Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of self-attention developed out of the sequence-to-sequence model architectures which were used primarily for machine translation. Here, the goal was to learn a single representation for an input sentence (\"encode\"), then use it to generate a translation (\"decode\").\n",
    "\n",
    "It however proved difficult to compress the information needed to translate a long sentence into a single representation. Bahadanau et. al. (2014) introduced the concept of attention -- the model could learn to use parts of the input sentence (\"attend\") directly while decoding rather than rely solely on the learnt representation. \n",
    "\n",
    "In my earlier post on [Nadaraya-Watson Regression](...), we saw how this non-parametric technique can be interpreted as an early form of attention. \n",
    "\n",
    "Vaswani el al. (2017) thus took this idea to its logical conclusion, realizing that the attention mechanism itself could be used as the basic non-linear transformation for sequences of variable length. The idea here is that the representation for every token can be expressed as a combination of the representations for every token. \n",
    "\n",
    "Each token representation can capture interactions between different tokens.  This also simplified the architecture considerably, allowing the model to process tokens in parallel by incorporating information about the position of a token within its embedding. Check out my post on positional embeddings [here](...).\n",
    "\n",
    "This new transformation can be stacked just like convolutions or feed-forward layers, allowing for deep networks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
