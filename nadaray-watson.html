<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Nadaraya-Watson Regression / Kernel Regression &#8212; Starburst AI Blog</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=12dfc556" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Explorations in AI" href="intro.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section class="tex2jax_ignore mathjax_ignore" id="nadaraya-watson-regression-kernel-regression">
<h1>Nadaraya-Watson Regression / Kernel Regression<a class="headerlink" href="#nadaraya-watson-regression-kernel-regression" title="Link to this heading">¶</a></h1>
<p>This is an early (from the 1960s) non-parametric regression method. The goal is to estimate the value of a function <span class="math notranslate nohighlight">\( m(x) = E[Y|X=x] \)</span> from training data
<span class="math notranslate nohighlight">\( \{(x_i, y_i) | x_i \in X, y_i \in Y, i=1,2,...,n\} \)</span>. <br />
<br />
As the term ‘non-parametric’ suggests, this is different from regression methods that involve assuming the shape of the function and then estimating the parameters. <br />
<br />
Instead, we will try to produce an estimate at a given point <span class="math notranslate nohighlight">\( x \)</span> using a weighted combination of the available data. <br />
The weights will be generated using a scalar-valued function <span class="math notranslate nohighlight">\( f(x, x_i) = \phi(||x - x_i||) \)</span>. <br />
The idea here is that the contribution of each data-point or feature <span class="math notranslate nohighlight">\( x_i \)</span> diminishes as the distance between <span class="math notranslate nohighlight">\( x \)</span> and <span class="math notranslate nohighlight">\( x_i \)</span> increases. <br />
Intuitively, this means that data-points closer to <span class="math notranslate nohighlight">\( x \)</span> should contribute more to our estimate, while ones that are farther away should contribute less. <br />
<br />
The function <span class="math notranslate nohighlight">\( f(x, x_i) \)</span> is called a kernel. Commonly used kernels include:</p>
<p>Gaussian</p>
<div class="math notranslate nohighlight">
\[ 
f(x,x_i) = exp(-\frac{||x-x_i||^2}{h}) 
\]</div>
<p>Boxcar</p>
<div class="math notranslate nohighlight">
\[
f(x,x_i) = 1 \text{  if   } \frac{||x-x_i||}{h} \leq 1 
\]</div>
<p>Epanechikov</p>
<div class="math notranslate nohighlight">
\[
f(x,x_i) =  max(0, 1- \frac{||x-x_i||}{h})
\]</div>
<p>We usually include a parameter <span class="math notranslate nohighlight">\(h\)</span> that controls the smoothness of the estimated function. Intuitively, this is a way of controlling how much a single data point can influence the
result. <br />
For our experiment, we will use a Gaussian kernel.</p>
<section id="let-s-start-by-generating-the-data">
<h2>Let’s start by generating the data.<a class="headerlink" href="#let-s-start-by-generating-the-data" title="Link to this heading">¶</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>


<span class="k">def</span> <span class="nf">wavyline</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">k</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">x</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">wavyline</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="n">x_gt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">y_gt</span> <span class="o">=</span> <span class="n">wavyline</span><span class="p">(</span><span class="n">x_gt</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_gt</span><span class="p">,</span> <span class="n">y_gt</span><span class="p">,</span> <span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Raw/Noisy measurements&#39;</span><span class="p">,</span> <span class="s1">&#39;Data source or process&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

</pre></div>
</div>
<p><img alt="png" src="_images/nadaray-watson_3_0.png" /></p>
<p>As you can see, we have generated 40 noisy datapoints for this curve.</p>
</section>
<section id="now-let-s-run-the-regression-on-our-training-data">
<h2>Now, let’s run the regression on our training data<a class="headerlink" href="#now-let-s-run-the-regression-on-our-training-data" title="Link to this heading">¶</a></h2>
<p>Using our Gaussian kernel function, we can estimate the curve from the data with a weighted average of the kernel at different points.</p>
<div class="math notranslate nohighlight">
\[
\hat{y} = \sum_i y_i* \frac{\phi(||x-x_i||)}{\sum_j \phi(||x-x_j||)}
\]</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">h</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">nadaraya_watson_regression</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_gt</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>

    <span class="n">distances</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">x_gt</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">distances</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">norm_weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">/</span> <span class="n">weights</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_train</span><span class="nd">@norm_weights</span>
    <span class="k">return</span> <span class="n">y_pred</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">nadaraya_watson_regression</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_gt</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_gt</span><span class="p">,</span> <span class="n">y_gt</span><span class="p">,</span> <span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_gt</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Raw/Noisy measurements&#39;</span><span class="p">,</span> <span class="s1">&#39;Data source or process&#39;</span><span class="p">,</span> <span class="s1">&#39;Prediction&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

</pre></div>
</div>
<p><img alt="png" src="_images/nadaray-watson_5_0.png" /></p>
<p>The green curve is a fairly good approximation of the original source or process curve, without learning any parameters!</p>
<p>We can experiment with different values of smoothing constant <span class="math notranslate nohighlight">\( h \)</span>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred_0_1</span> <span class="o">=</span> <span class="n">nadaraya_watson_regression</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_gt</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">y_pred_0_5</span> <span class="o">=</span> <span class="n">nadaraya_watson_regression</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_gt</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">y_pred_1_5</span> <span class="o">=</span> <span class="n">nadaraya_watson_regression</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_gt</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
</pre></div>
</div>
<p><video src="./media/videos/ml-basics//720p30/MyScene.mp4" controls></video></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">manim</span> <span class="o">-</span><span class="n">qm</span> <span class="o">-</span><span class="n">v</span> <span class="n">WARNING</span> <span class="n">MyScene</span>

<span class="k">class</span> <span class="nc">MyScene</span><span class="p">(</span><span class="n">Scene</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="n">ax</span> <span class="o">=</span> <span class="n">Axes</span><span class="p">(</span><span class="n">x_range</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">y_range</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">axis_config</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;include_numbers&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span>

        <span class="n">f1</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot_line_graph</span><span class="p">(</span><span class="n">x_gt</span><span class="p">,</span> <span class="n">y_pred_0_1</span><span class="p">,</span> <span class="n">add_vertex_dots</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">f2</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot_line_graph</span><span class="p">(</span><span class="n">x_gt</span><span class="p">,</span> <span class="n">y_pred_0_5</span><span class="p">,</span> <span class="n">add_vertex_dots</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">f3</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot_line_graph</span><span class="p">(</span><span class="n">x_gt</span><span class="p">,</span> <span class="n">y_pred_1_5</span><span class="p">,</span> <span class="n">add_vertex_dots</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">):</span>
            <span class="n">dot</span> <span class="o">=</span> <span class="n">Dot</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">c2p</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">dot</span><span class="p">)</span>
        

        <span class="bp">self</span><span class="o">.</span><span class="n">play</span><span class="p">(</span><span class="n">Transform</span><span class="p">(</span><span class="n">f1</span><span class="p">,</span> <span class="n">f2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">f1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">f2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">play</span><span class="p">(</span><span class="n">Transform</span><span class="p">(</span><span class="n">f2</span><span class="p">,</span> <span class="n">f3</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>




</pre></div>
</div>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Manim Community <span style="color: #008000; text-decoration-color: #008000">v0.18.1</span>

</pre>
<video src="media/jupyter/MyScene@2024-09-23@20-54-05.mp4" controls autoplay loop style="max-width: 60%;"  >
      Your browser does not support the <code>video</code> element.
    </video>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="intro.html">
              <img class="logo" src="_static/logo.png" alt="Logo of Project name not set"/>
            </a></p>
<h1 class="logo"><a href="intro.html">Project name not set</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Nadaraya-Watson Regression / Kernel Regression</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="intro.html">Documentation overview</a><ul>
      <li>Previous: <a href="intro.html" title="previous chapter">Explorations in AI</a></li>
  </ul></li>
</ul>
</div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2023.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.4.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="_sources/nadaray-watson.md"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>