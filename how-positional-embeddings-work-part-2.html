<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>How Positional Embeddings Work? Part 2 &#8212; Vikram&#39;s Data Science Blog</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=3eba45b5" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="icon" href="_static/starburst (200 x 200 px).png"/>
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section class="tex2jax_ignore mathjax_ignore" id="how-positional-embeddings-work-part-2">
<h1>How Positional Embeddings Work? Part 2<a class="headerlink" href="#how-positional-embeddings-work-part-2" title="Link to this heading">Â¶</a></h1>
<p>The attention mechanism computes dot products between projections of embeddings.</p>
<div class="math notranslate nohighlight">
\[
\sum_i W_i cos(\theta_{t + k} - \theta{t})
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sequence_length</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">embedding_length</span> <span class="o">=</span> <span class="mi">9</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">jax.numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jnp</span>

<span class="k">def</span><span class="w"> </span><span class="nf">pos</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">t</span> <span class="o">/</span> <span class="p">(</span><span class="mf">100.0</span><span class="o">**</span><span class="p">(</span><span class="n">i</span><span class="o">/</span><span class="n">embedding_length</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">i</span><span class="o">%</span><span class="k">2</span> == 0, jnp.sin(x), jnp.cos(x))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">jax</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax.numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jnp</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">generate_embeddings</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">sequence_length</span><span class="p">,</span> <span class="n">embedding_length</span><span class="p">),</span> <span class="n">min_val</span><span class="o">=-</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">max_val</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">minval</span><span class="o">=</span><span class="n">min_val</span><span class="p">,</span> <span class="n">maxval</span><span class="o">=</span><span class="n">max_val</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">embeddings</span>

<span class="n">sem_embeddings</span> <span class="o">=</span> <span class="n">generate_embeddings</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">jax.numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jnp</span>

<span class="k">def</span><span class="w"> </span><span class="nf">generate_pos_embeddings</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">sequence_length</span><span class="p">,</span> <span class="n">embedding_length</span><span class="p">)):</span>

    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">embeddings</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">at</span><span class="p">[(</span><span class="n">row</span><span class="p">,</span><span class="n">col</span><span class="p">)]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">pos</span><span class="p">(</span><span class="n">row</span><span class="p">,</span><span class="n">col</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">embeddings</span>

<span class="n">pos_embeddings</span> <span class="o">=</span> <span class="n">generate_pos_embeddings</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">generate_dataset</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">dataset</span><span class="p">):</span>

    <span class="n">i_values</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="p">(</span><span class="n">num_samples</span><span class="p">,),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">j_values</span> <span class="o">=</span> <span class="n">i_values</span> <span class="o">+</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">rng</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">num_samples</span><span class="p">,),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">10</span> <span class="o">-</span> <span class="n">i_values</span><span class="p">)</span>
    <span class="n">j_values</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">j_values</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>

    <span class="n">emb_i</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">i_values</span><span class="p">,:]</span>
    <span class="n">emb_j</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">j_values</span><span class="p">,</span> <span class="p">:]</span>

    <span class="n">diff</span> <span class="o">=</span> <span class="n">j_values</span> <span class="o">-</span> <span class="n">i_values</span>

    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">emb_i</span><span class="p">,</span> <span class="n">emb_j</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">diff</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">jax</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">flax.nnx</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nnx</span>

<span class="k">class</span><span class="w"> </span><span class="nc">AttnBlock</span><span class="p">(</span><span class="n">nnx</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">rngs</span><span class="p">:</span> <span class="n">nnx</span><span class="o">.</span><span class="n">Rngs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q</span> <span class="o">=</span> <span class="n">nnx</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">rngs</span><span class="o">=</span><span class="n">rngs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">nnx</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">rngs</span><span class="o">=</span><span class="n">rngs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">nnx</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">rngs</span><span class="o">=</span><span class="n">rngs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># B x T x E</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">att</span> <span class="o">=</span> <span class="n">q</span> <span class="o">@</span> <span class="n">k</span> <span class="o">/</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># B x T x T </span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">att</span> <span class="o">@</span> <span class="n">v</span> <span class="c1"># B x T x E</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">k</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">rngs</span> <span class="o">=</span> <span class="n">nnx</span><span class="o">.</span><span class="n">Rngs</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">pos_embeddings</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">attnblk</span> <span class="o">=</span> <span class="n">AttnBlock</span><span class="p">(</span><span class="n">embedding_length</span><span class="p">,</span> <span class="n">rngs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">attnblk</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">TypeError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">line</span> <span class="mi">24</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span> <span class="n">x</span> <span class="o">=</span> <span class="n">pos_embeddings</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="p">:]</span>
<span class="g g-Whitespace">     </span><span class="mi">23</span> <span class="n">attnblk</span> <span class="o">=</span> <span class="n">AttnBlock</span><span class="p">(</span><span class="n">embedding_length</span><span class="p">,</span> <span class="n">rngs</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">24</span> <span class="n">x</span> <span class="o">=</span> <span class="n">attnblk</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="nn">Cell In[5], line 15,</span> in <span class="ni">AttnBlock.__call__</span><span class="nt">(self, x)</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span> <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">13</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">15</span> <span class="n">att</span> <span class="o">=</span> <span class="n">q</span> <span class="o">@</span> <span class="n">k</span> <span class="o">/</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># B x T x T </span>
<span class="g g-Whitespace">     </span><span class="mi">16</span> <span class="n">x</span> <span class="o">=</span> <span class="n">att</span> <span class="o">@</span> <span class="n">v</span> <span class="c1"># B x T x E</span>
<span class="g g-Whitespace">     </span><span class="mi">17</span> <span class="k">return</span> <span class="n">x</span>

<span class="nn">File ~/dev/vikrampawar.com/.venv/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:579,</span> in <span class="ni">_defer_to_unrecognized_arg.&lt;locals&gt;.deferring_binary_op</span><span class="nt">(self, other)</span>
<span class="g g-Whitespace">    </span><span class="mi">577</span> <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span> <span class="k">if</span> <span class="n">swap</span> <span class="k">else</span> <span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">578</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">_accepted_binop_types</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">579</span>   <span class="k">return</span> <span class="n">binary_op</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">580</span> <span class="c1"># Note: don&#39;t use isinstance here, because we don&#39;t want to raise for</span>
<span class="g g-Whitespace">    </span><span class="mi">581</span> <span class="c1"># subclasses, e.g. NamedTuple objects that may override operators.</span>
<span class="g g-Whitespace">    </span><span class="mi">582</span> <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="ow">in</span> <span class="n">_rejected_binop_types</span><span class="p">:</span>

    <span class="p">[</span><span class="o">...</span> <span class="n">skipping</span> <span class="n">hidden</span> <span class="mi">15</span> <span class="n">frame</span><span class="p">]</span>

<span class="nn">File ~/dev/vikrampawar.com/.venv/lib/python3.12/site-packages/jax/_src/numpy/tensor_contractions.py:243,</span> in <span class="ni">matmul</span><span class="nt">(a, b, precision, preferred_element_type)</span>
<span class="g g-Whitespace">    </span><span class="mi">241</span> <span class="n">a</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">a_squeeze</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">242</span> <span class="n">b</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">b_squeeze</span><span class="p">))</span>
<span class="ne">--&gt; </span><span class="mi">243</span> <span class="n">out</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">dot_general</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">244</span>   <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="p">(((</span><span class="n">np</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,),</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">b_is_mat</span><span class="p">,)),</span> <span class="p">(</span><span class="n">a_batch</span><span class="p">,</span> <span class="n">b_batch</span><span class="p">)),</span>
<span class="g g-Whitespace">    </span><span class="mi">245</span>   <span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">,</span> <span class="n">preferred_element_type</span><span class="o">=</span><span class="n">preferred_element_type</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">246</span> <span class="n">result</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">perm</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">247</span> <span class="k">return</span> <span class="n">lax_internal</span><span class="o">.</span><span class="n">_convert_element_type</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">preferred_element_type</span><span class="p">,</span> <span class="n">output_weak_type</span><span class="p">)</span>

    <span class="p">[</span><span class="o">...</span> <span class="n">skipping</span> <span class="n">hidden</span> <span class="mi">9</span> <span class="n">frame</span><span class="p">]</span>

<span class="nn">File ~/dev/vikrampawar.com/.venv/lib/python3.12/site-packages/jax/_src/lax/lax.py:4977,</span> in <span class="ni">_dot_general_shape_rule</span><span class="nt">(lhs, rhs, dimension_numbers, precision, preferred_element_type, out_sharding)</span>
<span class="g g-Whitespace">   </span><span class="mi">4974</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">core</span><span class="o">.</span><span class="n">definitely_equal_shape</span><span class="p">(</span><span class="n">lhs_contracting_shape</span><span class="p">,</span> <span class="n">rhs_contracting_shape</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">4975</span>   <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;dot_general requires contracting dimensions to have the same &quot;</span>
<span class="g g-Whitespace">   </span><span class="mi">4976</span>          <span class="s2">&quot;shape, got </span><span class="si">{}</span><span class="s2"> and </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">4977</span>   <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lhs_contracting_shape</span><span class="p">,</span> <span class="n">rhs_contracting_shape</span><span class="p">))</span>
<span class="g g-Whitespace">   </span><span class="mi">4979</span> <span class="k">return</span> <span class="n">_dot_general_shape_computation</span><span class="p">(</span><span class="n">lhs</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">rhs</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dimension_numbers</span><span class="p">)</span>

<span class="ne">TypeError</span>: dot_general requires contracting dimensions to have the same shape, got (9,) and (3,).
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="n">src</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">],</span>
                    <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">23</span><span class="p">]])</span>
<span class="c1"># shape = (2 rows, 4 columns)</span>

<span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>   <span class="c1"># for output row 0, cols â [src[0,3], src[0,1]]</span>
                    <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>  <span class="c1"># for output row 1, cols â [src[1,2], src[1,0]]</span>
<span class="c1"># shape = (2 rows, 2 âgatheredâ columns)</span>

<span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">idx</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[13, 11],
        [22, 20]])
</pre></div>
</div>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="intro.html">
              <img class="logo" src="_static/starburst_narrow.png" alt="Logo of Starburst Data Science Blog"/>
            </a></p>
<h1 class="logo"><a href="intro.html">Starburst Data Science Blog</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="how-batchnorm-works-part-2.html">How Does Batch Normalization Work? Part 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="how-residual-connections-work.html">How Do Residual Connections Work?</a></li>
<li class="toctree-l1"><a class="reference internal" href="how-positional-embeddings-work.html">How do Positional Embeddings Work?</a></li>
<li class="toctree-l1"><a class="reference internal" href="how-dropout-works.html">How and Why Does Dropout Work?</a></li>
<li class="toctree-l1"><a class="reference internal" href="how-batchnorm-works.html">How Does Batch Normalization Work? Part 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="nadaraya-watson-kernel-regression.html">Nadaraya-Watson Regression</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="intro.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;Vikram Pawar [novastar53.github.io].
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.4.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="_sources/how-positional-embeddings-work-part-2.ipynb"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>